*** 2005-06-09

-- Generate three passwords (repeat until good passwords)
sh Utilities/WordMunger
sh Utilities/WordMunger
sh Utilities/WordMunger

-- Initialise passwords (prompted on first login, just exit)
sqlplus cms_transfermgmt_sc@cmssg
sqlplus cms_transfermgmt_sc_reader@cmssg
sqlplus cms_transfermgmt_sc_writer@cmssg

-- Load initial schema
cd Schema
perl -p -i -e 's/([ ])CMS_TRANSFERMGMT_INDX01/${1}CMS_TRANSFERMGMT_SC_INDX01/g' *.sql
sqlplus cms_transfermgmt_sc/<password>@cmssg @OracleInit.sql
perl -p -i -e 's/([ ])CMS_TRANSFERMGMT_SC_INDX01/${1}CMS_TRANSFERMGMT_INDX01/g' *.sql
cd ..

-- Create roles and apply privileges
sh Utilities/WordMunger
Schema/OracleNewRole.sh cms_transfermgmt_sc/<password>@cmsssg \
  site_cern <newpass>
Schema/OraclePrivs.sh cms_transfermgmt_sc/<password>@cmssg \
  cms_transfermgmt_sc_reader cms_transfermgmt_sc_writer
Schema/OracleSyns.sh cms_transfermgmt_sc \
  cms_transfermgmt_sc/<password>@cmssg \
  cms_transfermgmt_sc_reader/<password>n@cmssg
Schema/OracleSyns.sh cms_transfermgmt_sc \
  cms_transfermgmt_sc/<password>@cmssg \
  cms_transfermgmt_sc_writer/<password>n@cmssg

sqlplus cms_transfermgmt_sc/<password>@cmsssg
  insert into t_authorisation values (1118335369, 'SITE_CERN',
     'lassi.tuura@cern.ch', '/C=CH/O=CERN/OU=GRID/CN=Lassi Tuura 3370');

-- Prepare DBParam
Section                 SC3/Admin
Interface               Oracle
Database                cmssg
AuthDBUsername          cms_transfermgmt_sc
AuthDBPassword          <password>
ConnectionLife          86400
LogConnection           on
LogSQL                  off

Section                 SC3/CERN
Interface               Oracle
Database                cmssg
AuthDBUsername          cms_transfermgmt_sc_writer
AuthDBPassword          <password>
AuthRole                site_cern
AuthRolePassword        <password>
ConnectionLife          86400
LogConnection           on
LogSQL                  off

Section                 SC3/Reader
Interface               Oracle
Database                cmssg
AuthDBUsername          cms_transfermgmt_sc_reader
AuthDBPassword          <passsword>
ConnectionLife          86400
LogConnection           on
LogSQL                  off

-- Test
Utilities/DBDump -db Schema/DBParam:SC3/Admin t_node
Utilities/DBDump -db Schema/DBParam:SC3/CERN t_node
Utilities/DBDump -db Schema/DBParam:SC3/Reader t_node

-- Stats
Schema/OracleStatsEnable.sh cms_transfermgmt_sc/<password>@cmssg
Schema/OracleStatsUpdate.sh cms_transfermgmt_sc/<password>@cmssg

-- Copy data
sqlplus cms_transfermgmt_sc/<password>@cmssg
  insert into t_node values ('T1_CERN_MSS');

./Utilities/NodeNew T1_CERN_Buffer srm:gsiftp srm:gsiftp T1_CERN_MSS:1 |
   sqlplus cms_transfermgmt_sc/<password>@cmssg

sqlplus cms_transfermgmt_sc_writer/<password>@cmssg
  set role site_cern identified by <password>;
  copy from cms_transfermgmt/<password>@cms insert t_file using
    select * from t_file where filesize >= 400*1024*1024 and node like 'T1_CERN%';
  copy from cms_transfermgmt/<password>@cms insert t_file_attributes using
    select * from t_file_attributes where guid in
      (select guid from t_file where filesize >= 400*1024*1024 and node like 'T1_CERN%');
  insert into t_replica_state
      (select timestamp, guid, 'T1_CERN_MSS', 0, timestamp from t_file);
  insert into t_block
      (select min(timestamp), inblock, substr(inblock, 1, instr(inblock, '/')-1),
              substr(inblock, instr(inblock, '/')+1), count(guid), sum(filesize), 1
       from t_file group by inblock);

-- On cmsgate, initialise agent area
cd /data
mkdir SC3Nodes
cd SC3Nodes
ln -s ../V2Nodes/gridcert .
cvs -d :pserver:anonymous@cmscvs.cern.ch:/cvs_server/repositories/PHEDEX co PHEDEX

mkdir tools
VO_CMS_SW_DIR=/afs/cern.ch/sw PHEDEX/Deployment/InstallPOOL -arch SLC3 -cms $PWD/tools
PHEDEX/Deployment/InstallOracleClient /data/oracle $PWD/tools
PHEDEX/Deployment/InstallPerlModules $PWD/tools

# scp Schema/DBParam phedex@cmsgate.cern.ch:/data/SC3Nodes/PHEDEX/Schema
: source ./tools/poolenv.sh
: source ./tools/oraenv.sh 
: source ./tools/perlenv.sh
PHEDEX/Deployment/TestInstallation -db PHEDEX/Schema/DBParam:SC3/CERN \
  -poolcat mysqlcatalog_mysql://phedex:phedex@cmslcgco04/phedexcat

-- Cycle agents
PHEDEX/Utilities/Master -config PHEDEX/Custom/CERN/Config.SC3 start
PHEDEX/Utilities/Master -config PHEDEX/Custom/CERN/Config.SC3 stop

-- Make sure others can operate it all
chgrp -R phedex /data/SC3Nodes
chmod -R g+w /data/SC3Nodes
chmod o-rwx /data/SC3Nodes/PHEDEX/Schema/DBParam


*** 2005-06-10

-- Mark all blocks closed in sqlplus
update t_block set isopen = 0;

*** 2005-06-23
-- Recreate t_authorisation with new sizes
cd Schema
perl -p -i -e 's/([ ])CMS_TRANSFERMGMT_INDX01/${1}CMS_TRANSFERMGMT_SC_INDX01/g' OracleCoreAuth.sql
sqlplus cms_transfermgmt_sc/<password>@cmssg @OracleCoreAuth.sql
perl -p -i -e 's/([ ])CMS_TRANSFERMGMT_SC_INDX01/${1}CMS_TRANSFERMGMT_INDX01/g' OracleCoreAuth.sql
cd ..

-- Copy nodes from production database
copy from cms_transfermgmt_reader/<password>@cms insert t_node using
  select * from t_node where name not like '%CERN%';
copy from cms_transfermgmt_reader/<password>@cms insert t_node_neighbour using
  select * from t_node_neighbour where node != 'T1_CERN_MSS' and neighbour != 'T1_CERN_MSS';
copy from cms_transfermgmt_reader/<password>@cms insert t_node_import using
  select * from t_node_import where node not like '%CERN%';
copy from cms_transfermgmt_reader/<password>@cms insert t_node_export using
  select * from t_node_export where node not like '%CERN%';

-- Generate roles
cd /data/SC3Nodes/Keys
(initrole="../PHEDEX/Schema/OracleInitRole.sh ../PHEDEX/Schema/DBParam SC3 $PWD"
 $initrole "alessandra.fanfani@bo.infn.it"            bologna
 $initrole "anastasios.papageorgiou@imperial.ac.uk"   imperial
 $initrole "bbockelm@math.unl.edu"                    nebraska
 $initrole "chia-ming.kuo@cern.ch"                    ascc
 $initrole "chia-ming.kuo@cern.ch"                    ncu
 $initrole "daniele.bonacorsi@bo.infn.it"             cnaf
 $initrole "federico.calzolari@sns.it"                pisa
 $initrole "francesco.safaitehrani@roma1.infn.it"     rome
 $initrole "giacinto.donvito@ba.infn.it"              bari
 $initrole "igor.semeniouk@poly.in2p3.fr"             in2p3
 $initrole "jens.rehn@cern.ch"                        karlsruhe
 $initrole "jose.hernandez@ciemat.es"                 pic
 $initrole "jose.hernandez@ciemat.es"                 ciemat
 $initrole "jose.hernandez@ciemat.es"                 lcgprod
 $initrole "jens.rehn@cern.ch"                        fzk
 $initrole "lassi.tuura@cern.ch"                      cern
 $initrole "letts@physics.ucsd.edu"                   ucsd
 $initrole "massimo.biasotto@lnl.infn.it"             legnaro
 $initrole "michael.ernst@desy.de"                    desy
 $initrole "tim.barrass@bris.ac.uk"                   ral
 $initrole "yujun@fnal.gov"                           fnal)

*** 2005-06-23
--- Load files into LFC
: cd /data/SC3Nodes/PHEDEX 
: eval $(Utilities/Master -config Custom/CERN/Config.SC3 environ)
: cd /data/Inject/Mirror 
: (for dir in PTDR DC04 Validation; do
   for f in $dir/*_*/*/POOL_Catalogue_PCP.*.xml.xfer; do
     echo "processing $f" $(stat -c '%s' $f)
     POOL_XMLBACKUP=0 POOL_OUTMSG_LEVEL=E \
     FCpublish -m 50000 \
       -d lfccatalog_lfc://lfc-cms-test.cern.ch/grid/cms/sc3-guid-index \
       -u file:$f || echo "*** $f failed with exit $?"
   done &
 done; wait) >>& lfc-pub.txt </dev/null

-- Send out the role e-mails
: cd /data/SC3Nodes/Keys/Output
: for f in *:*; do                                                                                                                                                  
    site=$(echo $f | sed 's/:.*//; s/^site_//' | tr '[:lower:]' '[:upper:]')
    email=$(echo $f | sed 's/[^:]*://')
    (echo "Subject: PhEDEx authentication role for SC3/$site"
     echo "To: $email"; echo "Cc: lassi.tuura@cern.ch, tim.barrass@physics.org"
     echo; cat $f) | /usr/sbin/sendmail -t -f lassi.tuura@cern.ch
  done

-- Load information about the zips
source /data/SC3Nodes/tools/poolenv.sh
source /data/SC3Nodes/tools/oraenv.sh
source /data/SC3Nodes/tools/perlenv.sh
cd /data/Inject/Zips
rsync -avuz /afs/cern.ch/user/c/cmsprod/w6/Zip/drop/ drop/

# Uncompress
(for x in $(ls drop | sed 's/_.*//' | sort | uniq); do
   for f in drop/$x*/*.gz; do
     [ -f ${f:r} -a ! ${f:r} -ot $f ] && continue
     gzip -dc < $f > ${f:r} && touch -r $f ${f:r}
   done &
 done; wait)

# Select files we need (the zips) and fix paths
(for x in $(ls drop | sed 's/_.*//' | sort | uniq); do
   for f in drop/$x*/XMLCatFragment.*.txt; do
     [ -f $f.xfer -a ! $f.xfer -ot $f ] && continue
     echo "processing $f" $(stat -c '%s' $f)
     /data/SC3Nodes/PHEDEX/Utilities/FCcopy -u XML:$f -d XML:$f.xfer.new \
        -m '/castor/cern.ch/cms/%' &&
        perl -p -i -e 's|/castor|rfio:/castor|g' $f.xfer.new &&
        mv $f.xfer.new $f.xfer &&
        touch -r $f $f.xfer
   done &
 done; wait) >>& zip-xml.txt </dev/null

# Publish to TMDB
(for x in $(ls drop | sed 's/_.*//' | sort | uniq); do
   for f in drop/$x*/XMLCatFragment.*.txt.xfer; do
     [ -f $f.inj -a ! $f.inj -ot $f ] && continue
     echo "processing $f" $(stat -c '%s' $f)
     /data/SC3Nodes/PHEDEX/Toolkit/Request/TMDBInject \
       -catalogue $f -cksums ${f:r:s/XMLCatFragment/CheckSum} -nodes T1_CERN_MSS \
       -db /data/SC3Nodes/PHEDEX/Schema/DBParam:SC3/Admin &&
       touch -r $f $f.inj
   done &
 done; wait) >>& zip-inject.txt </dev/null

# Publish to LFC
(for x in $(ls drop | sed 's/_.*//' | sort | uniq); do
   for f in drop/$x*/XMLCatFragment.*.txt.xfer; do
     [ -f $f.pub -a ! $f.pub -ot $f ] && continue
     echo "processing $f" $(stat -c '%s' $f)
     # lfccatalog_lfc://lfc-cms-test.cern.ch/grid/cms/sc3-guid-index
     # mysqlcatalog_mysql://phedex:phedex@cmslcgco04.cern.ch/phedexcat
     POOL_XMLBACKUP=0 POOL_OUTMSG_LEVEL=E \
     FCpublish -m 50000 \
       -d mysqlcatalog_mysql://phedex:phedex@cmslcgco04.cern.ch/phedexcat \
       -u file:$f
     s=$?; if [ $s != 0 ]; then echo "*** $f failed with exit $s";
     else touch -r $f $f.pub; fi
   done &
 done; wait) >>& zip-pub.txt </dev/null

# Delete previous set of test files
sqlplus $(Schema/OracleConnectId -db Schema/DBParam:SC3/Admin)
  delete from t_file_attributes where guid in
    (select guid from t_file where lfn not like 'Z%');
  delete from t_replica_state where guid in
    (select guid from t_file where lfn not like 'Z%');
  delete from t_file where lfn not like 'Z%';
  delete from t_block where name in
    (select name from t_block left join t_file on inblock = name where inblock is null);
  update t_block set (files, bytes) =
    (select count(guid), sum(filesize) from t_file where inblock = name);

# Default most nodes to transfer with srm protocol
sqlplus $(Schema/OracleConnectId -db Schema/DBParam:SC3/Admin)
  delete from t_node_import where node like 'T1_%' and protocol = 'gsiftp';
  insert into t_node_import
    (select name, 'srm', 0 from t_node
     left join t_node_import on name = node
     where node is null and name like '%_Buffer');

# Subscribe all MSS nodes and all T2 buffer nodes to all files
insert into t_subscription
  (select b.owner, b.dataset, n.name from t_block b, t_node n
   where (n.name like '%MSS' or n.name like 'T2%Buffer')
    and n.name not like '%CERN%'
    and not exists (select * from t_subscription s where
                    s.owner = b.owner and s.dataset = b.dataset
                    and s.destination = n.name));

*** 2005-06-30

-- Create a "static" catalogue as fallback for testing
(eval $(cd /data/SC3Nodes/PHEDEX; Utilities/Master -config Custom/CERN/Config.SC3 environ)
 for x in $(ls drop | sed 's/_.*//' | sort | uniq); do
   for f in drop/$x*/XMLCatFragment.*.txt.xfer; do
   perl -I$PHEDEX_SCRIPTS/Toolkit/Common -e '
     use UtilsReaders;
     my (%known, %seen);
     foreach $cat (@ARGV) {
       do { local $|=1; print "processing $cat @{[-s $cat]}\n" };
       open(ST, "> $cat.static") or die "$cat.static: $!\n";
       my $c = eval { &readXMLCatalogue($cat) };
       do { print $@; close (ST); next; } if $@;
       print ST map { "$_->{GUID} $_->{PFN}[0]{PFN}\n" } @$c;
       close(ST);
     }' $f
   done &
 done; wait
 echo **/*.static | xargs cat > $PHEDEX_CUSTOM/StaticCatalogue.txt
 ) >>& zip-static.txt </dev/null

-- Clear out nodes
-- Delete from t_node_neighbour all nodes and links that should not exist.
-- Make sure topology is correct in t_node_neighbour (except NCU via CERN).
-- Delete all other noise:
delete from t_subscription where destination not in (select node from t_node_neighbour);
delete from t_block_destination where node not in (select node from t_node_neighbour);
delete from t_block_replica where node not in (select node from t_node_neighbour);
delete from t_node_import where node not in (select node from t_node_neighbour);
delete from t_node_export where node not in (select node from t_node_neighbour);
delete from t_routing where from_node not in (select node from t_node_neighbour);
delete from t_routing where to_node not in (select node from t_node_neighbour);
delete from t_node where name not in (select node from t_node_neighbour);


*** 2006-07-01

-- Reinitialise the set of files in TMDB from the published Zips.

-- 1. Stop agents.  Leave info-pm to clean t_transfer_completed,
--    then exit it as well.

-- 2. Clear files from mysql database:
delete from t_pfn where filetype = 'EVDZip';
delete from t_lfn where lfname like 'ZippedEVD%';
delete from t_meta where Content = 'ZippedEVD';

-- 3. Clear files from TMDB:
delete from t_subscription;

delete from t_block_destination;
delete from t_block_replica;
delete from t_block;

delete from t_transfer_state;
delete from t_replica_state;
delete from t_file_attributes;
delete from t_file;

-- 4. Restart agents.

-- 5. Clear /data/Inject/Zips/drop, and redo the procedures above
--    to refill TMDB and catalogue, and to make a static catalogue.
# rsync
# Uncompress
# Select files we need (the zips) and fix paths
# Create a "static" catalogue as fallback for testing
# Publish to TMDB
# Publish to LFC
# Subscribe all T1 MSS nodes to all files

-- 6. Make fake copies of files
Testbed/FileSources/SC3DuplicateFiles -db Schema/DBParam:SC3/Admin  


*** 2005-07-02

-- Redo the file replica creation: remove excess replicas, and prepare
-- to do it on demand (e.g. in cron job) as transfers progress, so the
-- file size distribution remains roughly correct at the destinations.
select * from t_block for update;
select * from t_transfer_state for update;
create table t_scratchme as select guid from t_file f
  where guid not like '%-%-%-%-%'
  and not exists (select rs.guid from t_replica_state rs
                  where rs.guid = f.guid and rs.node not like '%CERN%')
  and not exists (select ts.guid from t_transfer_state ts
                  where ts.guid = f.guid and ts.from_node like '%CERN%'
                  and to_state >= 2);
delete from t_transfer_state where guid in (select * from t_scratchme);
delete from t_replica_state where guid in (select * from t_scratchme);
delete from t_file_attributes where guid in (select * from t_scratchme);
delete from t_file where guid in (select * from t_scratchme);
update t_block set (files, bytes) =
  (select count(guid), sum(filesize) from t_file where inblock = name);
drop table t_scratchme;
