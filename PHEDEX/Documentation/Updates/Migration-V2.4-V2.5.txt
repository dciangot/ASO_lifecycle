** Migration procedure applied to Prod instance **

# Source environment
source ../sw/slc*/cms/PHEDEX/PHEDEX_*/etc/profile.d/env.sh

# Set authentication for DB access
export PHEDEX_DB='../SITECONF/CERN/PhEDEx/DBParam:Dev/Admin';
export PHEDEX_DB_R='../SITECONF/CERN/PhEDEx/DBParam:Dev/Reader';
export PHEDEX_DB_W='../SITECONF/CERN/PhEDEx/DBParam:Dev/CERN';


# Save all old tables to xt
sqlplus -S $(Schema/OracleConnectId  -db ${PHEDEX_DB}) @Schema/OracleSave.sql </dev/null

# Load the new schema
sqlplus -S $(Schema/OracleConnectId  -db ${PHEDEX_DB}) @Schema/OracleReset.sql </dev/null
sqlplus -S $(Schema/OracleConnectId  -db ${PHEDEX_DB}) @Schema/OracleInit.sql </dev/null
sqlplus -S $(Schema/OracleConnectId  -db ${PHEDEX_DB}) @Schema/OracleStatsEnable.sql </dev/null



# Connect to DB using SQLPlus
sqlplus $(Schema/OracleConnectId  -db ${PHEDEX_DB})

-- Disable all triggers
begin
  for o in (select trigger_name from user_triggers) loop
    execute immediate 'alter trigger ' || o.trigger_name || ' disable';
  end loop;
end;
/

-- Migrate old table content
insert into t_adm_node (id, name, kind, technology, se_name)
   (select seq_adm_node.nextval, name,
     case
       when (name like 'T1%Buffer'
	     or name like '%DESY%Buffer'
             or name like '%CERN%Export'
	     or name like '%SINP%Buffer')
	 then 'Buffer'
       when name like '%MSS'
         then 'MSS'
       else 'Disk'
     end,
     case
       when (name like '%ASGC%'
	     or name like '%CNAF%'
	     or name like '%CERN%'
	     or name like '%PIC%'
	     or name like '%RAL%')
	 then 'Castor'
       when (name like 'T1%')
         then 'dCache'
       when (name like '%CSCS%'
             or name like '%Pisa%'
	     or name like '%Rome%'
             or name like '%GRIF%'
	     or name like '%Taiwan%')
	 then 'DPM'
       else
         'dCache'
    end,
    'FIXME.se.name'
   from xt_node);

begin
  for o in (select id, name from t_adm_node) loop
    -- alter table t_x add partition node_t1_foo_buffer values (1);
    execute immediate 'alter table t_xfer_replica add partition node_' || lower(o.name) || ' values (' || o.id || ')';
    execute immediate 'alter table t_xfer_request add partition dest_' || lower(o.name) || ' values (' || o.id || ')';
    execute immediate 'alter table t_xfer_task    add partition to_'   || lower(o.name) || ' values (' || o.id || ')';
  end loop;
end;
/

insert into t_adm_link (id, from_node, to_node, distance, is_local, is_active, is_preferred, bandwidth_cap)
   (select seq_adm_link.nextval,
       (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = oldl.from_node ),
       (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = oldl.to_node ),
   oldl.distance, decode(oldl.local_boost,1,'y',0,'n'), 'n', 'n', oldl.bandwidth_cap
   from xt_link oldl);

insert into t_dps_dbs (id, name, dls, time_create)
   (select seq_dps_dbs.nextval, name, NVL(dls,'lfc:unknown'), time_create
   from xt_dps_dbs);

insert into t_dps_dataset (id, dbs, name, is_open, is_transient, time_create)
   (select seq_dps_dataset.nextval,
       (select ndbs.id from t_dps_dbs ndbs left join xt_dps_dbs odbs on ndbs.name = odbs.name where odbs.id = oldd.dbs),
    oldd.name, oldd.is_open, oldd.is_transient, oldd.time_create
   from xt_dps_dataset oldd);

insert into t_dps_block (id, dataset, name, files, bytes, is_open, time_create)
   (select seq_dps_block.nextval,
       (select newd.id from t_dps_dataset newd left join xt_dps_dataset oldd on newd.name = oldd.name
          left join t_dps_dbs newdbs on newdbs.id = newd.dbs left join xt_dps_dbs olddbs on olddbs.id = oldd.dbs
          where oldd.id = oldb.dataset and olddbs.name = newdbs.name),
       oldb.name, oldb.files, oldb.bytes, oldb.is_open, oldb.time_create
       from xt_dps_block oldb);

insert into t_dps_block_replica (block, node, is_active, src_files, src_bytes, dest_files, dest_bytes, node_files, node_bytes,
    xfer_files, xfer_bytes, time_create, time_update)
    (select
       (select newb.id from t_dps_block newb left join xt_dps_block oldb on newb.name = oldb.name
          left join t_dps_dataset newd on newb.dataset=newd.id left join xt_dps_dataset oldd on oldb.dataset = oldd.id
          where oldb.id = oldbr.block and oldd.name = newd.name),
       (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = oldbr.node ),
       oldbr.is_active, 0, 0,
       oldbr.dest_files, oldbr.dest_bytes, oldbr.node_files, oldbr.node_bytes, oldbr.xfer_files, oldbr.xfer_bytes,
       oldbr.time_create, oldbr.time_update
       from xt_dps_block_replica oldbr);

insert into t_dps_subscription (dataset, block, destination, priority, is_move, is_transient, time_create, time_complete, time_suspend_until)
   (select 
       (select newd.id from t_dps_dataset newd left join xt_dps_dataset oldd on newd.name = oldd.name where oldd.id = olds.dataset ),
       null,
       (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = olds.destination ),
   olds.priority, olds.is_move, olds.is_transient, olds.time_create, olds.time_complete, olds.time_suspend_until
   from xt_dps_subscription olds);

commit;

insert /*+ append */ into t_dps_file (id, node, inblock, logical_name, checksum, filesize, time_create)
   (select seq_dps_file.nextval,
       (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = oldf.node ),
       (select newb.id from t_dps_block newb left join xt_dps_block oldb on newb.name = oldb.name
           left join t_dps_dataset newd on newb.dataset=newd.id left join xt_dps_dataset oldd on oldb.dataset = oldd.id
           where oldb.id = oldf.inblock and oldd.name = newd.name),
   oldf.logical_name, oldf.checksum, oldf.filesize, oldf.time_create
   from xt_dps_file oldf);

commit;

insert /*+ append */ into t_xfer_file (id, inblock, logical_name, checksum, filesize)
   (select id, inblock, logical_name, checksum, filesize
    from t_dps_file);

commit;

insert /*+ append */ into t_xfer_replica (id, node, fileid, state, time_create, time_state)
    (select seq_xfer_replica.nextval,
       (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = oldr.node ),
       (select newf.id from t_dps_file newf left join xt_dps_file oldf on newf.logical_name = oldf.logical_name where oldf.id = oldr.fileid ),
    oldr.state, oldr.time_create, oldr.time_state
    from xt_xfer_replica oldr);

commit;

insert /*+ append */ into t_xfer_replica (id, node, fileid, state, time_create, time_state)
    (select seq_xfer_replica.nextval, br.node, f.id, 0, br.time_update, br.time_update
     from t_dps_block_replica br join t_dps_file f on f.inblock = br.block
     where br.is_active = 'n' and br.node_files > 0);

update t_dps_block_replica set is_active = 'y' where is_active = 'n';

merge into t_dps_block_replica br using
    (select inblock, node,
       max(time_create) ctime,
       count(id) files,
       sum(filesize) bytes
    from t_dps_file
    group by inblock, node) f
on (br.node = f.node and br.block = f.inblock)
when matched then
    update set
    br.src_files = f.files, br.src_bytes = f.bytes
when not matched then
    insert (br.block, br.node, br.is_active, br.src_files, br.src_bytes, br.dest_files, br.dest_bytes,
            br.node_files, br.node_bytes, br.xfer_files, br.xfer_bytes, br.time_create, br.time_update)
    values (f.inblock, f.node, 'y', f.files, f.bytes, 0, 0, 0, 0, 0, 0, f.ctime, f.ctime);

commit;


insert /*+ append */ all
  into t_history_link_stats (timebin, timewidth, from_node, to_node, priority,
			     pend_files, pend_bytes, wait_files, wait_bytes,
			     cool_files, cool_bytes, ready_files, ready_bytes,
			     xfer_files, xfer_bytes, confirm_files, confirm_bytes,
			     confirm_weight, param_rate, param_latency)
	             values (timebin, timewidth, from_node, to_node, priority,
			     pend_files, pend_bytes, wait_files, wait_bytes,
			     cool_files, cool_bytes, ready_files, ready_bytes,
			     xfer_files, xfer_bytes, confirm_files, confirm_bytes,
			     confirm_weight, param_rate, param_latency)
  into t_history_link_events (timebin, timewidth, from_node, to_node, priority,
			      avail_files, avail_bytes, done_files, done_bytes,
			      try_files, try_bytes, fail_files, fail_bytes,
			      expire_files, expire_bytes)
	              values (timebin, timewidth, from_node, to_node, priority,
			      avail_files, avail_bytes, done_files, done_bytes,
			      try_files, try_bytes, fail_files, fail_bytes,
			      expire_files, expire_bytes)
  select oldhl.timebin, oldhl.timewidth,
     (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = oldhl.from_node) from_node,
     (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = oldhl.to_node) to_node,
     oldhl.priority, oldhl.pend_files, oldhl.pend_bytes, oldhl.wait_files, oldhl.wait_bytes, oldhl.cool_files,
     oldhl.cool_bytes, oldhl.ready_files, oldhl.ready_bytes, oldhl.xfer_files, oldhl.xfer_bytes, oldhl.avail_files,
     oldhl.avail_bytes, oldhl.done_files, oldhl.done_bytes, oldhl.try_files, oldhl.try_bytes, oldhl.fail_files, oldhl.fail_bytes,
     oldhl.expire_files, oldhl.expire_bytes, oldhl.confirm_files, oldhl.confirm_bytes, oldhl.confirm_weight, oldhl.param_rate,
     oldhl.param_latency
  from xt_link_histogram oldhl;


insert /*+ append */ into t_history_dest (timebin, timewidth, node, dest_files, dest_bytes, node_files, node_bytes, request_files,
    request_bytes, idle_files, idle_bytes)
    (select oldhd.timebin, oldhd.timewidth,
        (select newn.id from t_adm_node newn left join xt_node oldn on newn.name = oldn.name where oldn.id = oldhd.node ),
    oldhd.dest_files, oldhd.dest_bytes, oldhd.node_files, oldhd.node_bytes, oldhd.request_files, oldhd.request_bytes,
    oldhd.idle_files, oldhd.idle_bytes
    from xt_dest_histogram oldhd);


-- Commit the modifications so far
commit;


-- Re-enable all triggers
begin
  for o in (select trigger_name from user_triggers) loop
    execute immediate 'alter trigger ' || o.trigger_name || ' enable';
  end loop;
end;
/

-- Drop ancient roles
begin
  for o in (select granted_role from user_role_privs
	    where granted_role like 'PROD%') loop
     dbms_output.put_line ('Dropping role ' || o.granted_role);
     execute immediate 'drop role ' || o.granted_role;
  end loop;
end;
/

-- modify node 

update t_adm_node set name='T2_GRIF_LLR' where name='T2_GRIF_Buffer';
update t_adm_node set name='T2_SouthGrid_RALPPD' where name='T2_RutherfordPPD';
update t_adm_node set name='T2_Spain_CIEMAT' where name='T2_Spain_Buffer';


# !! Quit SQLPlus session !!

# Create Web role
./Schema/OracleNewRole.sh $(Schema/OracleConnectId  -db ${PHEDEX_DB}) PHEDEX_WEBSITE_PROD <some_new_password>

# Import users/sites
./Utilities/ImportSites -db ${PHEDEX_DB} Documentation/Updates/sites.txt


# Add global admins
./Utilities/IdentityNew -db ${PHEDEX_DB} -dn '/C=CH/O=CERN/OU=GRID/CN=Dimitrije Maletic 2991' -email 'Dimitrije.Maletic@cern.ch' -global_admin
./Utilities/IdentityNew -db ${PHEDEX_DB} -dn '/C=CH/O=CERN/OU=GRID/CN=Douglas Teodoro 8147' -email 'Douglas.Teodoro@cern.ch' -global_admin
./Utilities/IdentityNew -db ${PHEDEX_DB} -dn '/C=UK/O=eScience/OU=Bristol/L=IS/CN=simon metson' -email 'simon.metson@cern.ch' -global_admin
./Utilities/IdentityNew -db ${PHEDEX_DB} -dn '/DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=rehn/CN=526374/CN=Jens Rehn' -email 'jens.rehn@cern.ch' -global_admin
./Utilities/IdentityNew -db ${PHEDEX_DB} -dn '/DC=org/DC=doegrids/OU=People/CN=Ricky Egeland 693921' -email 'Ricky.Egeland@cern.ch' -global_admin
./Utilities/IdentityNew -db ${PHEDEX_DB} -dn '/C=CH/O=CERN/OU=GRID/CN=Peter Kreuzer 3091' -email 'Peter.Kreuzer@cern.ch' -global_admin

# Creating synonyms for the other users
./Schema/OracleSyns.sh 'cms_transfermgmt' $(Schema/OracleConnectId  -db ${PHEDEX_DB}) $(Schema/OracleConnectId  -db ${PHEDEX_DB_R})
./Schema/OracleSyns.sh 'cms_transfermgmt' $(Schema/OracleConnectId  -db ${PHEDEX_DB}) $(Schema/OracleConnectId  -db ${PHEDEX_DB_W})

# Create privileges
./Schema/OraclePrivs.sh $(Schema/OracleConnectId  -db ${PHEDEX_DB}) 'cms_transfermgmt_reader' 'cms_transfermgmt_writer'

# Update statistics
sqlplus -S $(Schema/OracleConnectId  -db ${PHEDEX_DB}) @Schema/OracleStatsUpdate.sql </dev/null


** Migration of SC4 instance **

Folowed the steps for the Prod migration. Exceptions listed below.

1. Change settings
export PHEDEX_DB='../SITECONF/CERN/PhEDEx/DBParam:SC4/Admin';
export PHEDEX_DB_R='../SITECONF/CERN/PhEDEx/DBParam:SC4/Reader';
export PHEDEX_DB_W='../SITECONF/CERN/PhEDEx/DBParam:SC4/CERN';

2. Drop old roles
begin
  for o in (select granted_role from user_role_privs
	    where granted_role like 'SC4%') loop
     dbms_output.put_line ('Dropping role ' || o.granted_role);
     execute immediate 'drop role ' || o.granted_role;
  end loop;
end;
/

3. Set pasword for website
./Schema/OracleNewRole.sh $(Schema/OracleConnectId  -db ${PHEDEX_DB}) PHEDEX_WEBSITE_SC4 <some_new_password>

4. Import sites for SC4
./Utilities/ImportSites -db ${PHEDEX_DB} Documentation/Updates/sites_sc4.txt

5. Create privilege
./Schema/OraclePrivs.sh $(Schema/OracleConnectId  -db ${PHEDEX_DB}) 'cms_transfermgmt_sc_reader' 'cms_transfermgmt_sc_writer'
