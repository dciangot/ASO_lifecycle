#!/usr/bin/env perl

# outputs data for plotting
# x-axis:  time
# y-axis:  n_blocks :  number of blocks in the dataset under study
#          n_ideal1 :  ideally complete blocks, # attempts total / avg block size
#          n_ideal2 :  ideally complete blocks, # successes total / avg block size
#          n_pot    :  potentially complete blocks, # blocks with 1 attempt for each file
#          n_act    :  actually complete blocks, # blocks actually complete
#          n_a      :  # blocks with 1 attempted transfer
#          n_a25    :  # blocks with 0-25% of files attempted
#          n_a50    :  # blocks with 25-50% of files attempted
#          n_a75    :  # blocks with 50-75% of files attempted
#          n_a100   :  # blocks with 75-100% of files attempted
#          n_s      :  # blocks with 1 successful transfer
#          n_s25    :  # blocks with 0-25% of files successful
#          n_s50    :  # blocks with 25-50% of files successful
#          n_s75    :  # blocks with 50-75% of files successful
#          n_s100   :  # blocks with 75-100% of files successful
#          n_f      :  # blocks with 1 failed transfer
#          n_f25    :  # blocks with 0-25% attempts failed
#          n_f50    :  # blocks with 25-50% attempts failed
#          n_f75    :  # blocks with 50-75% attempts failed
#          n_f100   :  # blocks with 75-100% attempts failed
#          n_r      :  # blocks with 1 failure retried once
#          n_r25    :  # blocks with 0-25% of failures retried once
#          n_r50    :  # blocks with 25-50% of failures retried once
#          n_r75    :  # blocks with 50-75% of failures retried once
#          n_r100   :  # blocks with 75-100% of failures retried once


use warnings;
use strict;

use Data::Dumper;
use Getopt::Long;
use POSIX;

use PHEDEX::Core::DB;

my %opts;
GetOptions('database|db=s' => \$opts{DBPARAM},     # DBParam file
	   'dataset|ds=s'  => \$opts{DATASET},     # dataset to investigate
	   'log|f=s'       => \$opts{LOG},         # FilePump log
	   'to|t=s'        => \$opts{TO_NODE},     # destination node of the data
	   'binsize|b=i'   => \$opts{BINSIZE});    # granularity of the output, in minutes

my $dbparam = $opts{DBPARAM} or die "-database required";
my $dataset = $opts{DATASET} or die "-dataset required";
my $log = $opts{LOG} or die "-log required";
my $to_node = $opts{TO_NODE} or die "-to required";
my $binsize = $opts{BINSIZE} || 5;

my $self = { DBCONFIG => $dbparam };
my $dbh = &connectToDatabase ($self);

my $sql = qq{ select b.name block_name, b.time_create block_create, f.logical_name
	        from t_dps_dataset ds
                join t_dps_block b on b.dataset = ds.id
                join t_dps_file f on f.inblock = b.id
	       where ds.name = :dataset 
	      };

my $q = &dbexec($dbh, $sql, ':dataset' => $dataset);

my $blocks = {};
my $files = {};
while ( my ($block, $b_create, $file) = $q->fetchrow() ) {

    $blocks->{$block} = { 
	NAME => $block,
	BLOCK_CREATE => $b_create,
	FILES => [],
	ATTEMPTS => [],
	SUCCESSES => [],
	FAILURES => [],
	RETRIES => []
	} unless exists $blocks->{$block};

    $files->{$file} = { 
	NAME => $file,
	BLOCK => $blocks->{$block},
	ATTEMPTS => [],
	SUCCESSES => [],
	FAILURES => [],
	RETRIES => []
	};
    
    push @{$blocks->{$block}->{FILES}}, $files->{$file};
}

unless (scalar keys %$blocks > 0 && scalar keys %$files > 0) {
    die "Database query returned no results, check -dataset argument\n";
}


# Ordered array of block creation times
my @block_create;
my ($sum_bsize, $n_blocks) = (0, 0);
foreach my $block (sort { $a->{BLOCK_CREATE} <=> $b->{BLOCK_CREATE} } values %$blocks) {
    push @block_create, $block->{BLOCK_CREATE};
    my $n_files = scalar @{$block->{FILES}};
    $block->{N_FILES} = $n_files;
    $sum_bsize += $n_files;
    $n_blocks++;
}
my $avg_block_size = $sum_bsize / $n_blocks;

my $totals = { ATTEMPTS => [],
	       SUCCESSES => [],
	       FAILURES => [],
	       RETRIES => []
	       };

# result fields
my @r = qw( n_blocks n_ideal1 n_ideal2 n_pot n_act
	    n_a n_a25 n_a50 n_a75 n_a100
	    n_s n_s25 n_s50 n_s75 n_s100
	    n_f n_f25 n_f50 n_f75 n_f100
	    n_r n_r25 n_r50 n_r75 n_r100 );

my $start;

# print header
print join(',', 'timestamp', 'minute', @r), "\n";

open LOG, "< $log" or die $!;
while (<LOG>) {
    chomp $_;
    next unless $_ =~ /xstats/;
    $_ =~ s/^.*xstats:\s*//;

    my %h;
    foreach (split /\s+/, $_) {
	next unless $_ =~ /(.*)=(.*)/;
	$h{$1} = $2;
    }

    next unless $h{'to'} eq $to_node;
    my $file = $h{'lfn'};
    next unless exists $files->{$file};
    my $time = $h{'t-done'}; $start = $time unless $start;
    my $status = $h{'report-code'};

    my $fileref = $files->{$file};
    my $blockref = $files->{$file}->{BLOCK};

    foreach my $ref ( $fileref, $blockref, $totals ) {
	push @{$ref->{ATTEMPTS}}, $time;
	push @{$ref->{SUCCESSES}}, $time if $status == 0;
	push @{$ref->{FAILURES}}, $time if $status != 0;
	push @{$ref->{RETRIES}}, $time if scalar @{$fileref->{ATTEMPTS}} > 1;
    }

    # build result hash
    my %r = map { $_ => 0 } @r;

    # calculate completeness metrics for the block this file belongs to
    my ($n_files, $n_a1, $n_a, $n_s, $n_f, $n_r) = (0,0,0,0,0,0);
    foreach my $file ( @{$blockref->{FILES}} ) {
	$n_files++;
	$n_a1++ if scalar @{$file->{ATTEMPTS}} > 0;
	$n_a += scalar @{$file->{ATTEMPTS}};
	$n_s += scalar @{$file->{SUCCESSES}};
	$n_f += scalar @{$file->{FAILURES}};
	$n_r += scalar @{$file->{RETRIES}};
    }
    $blockref->{N_FILES} = $n_files;
    $blockref->{N_UNQ_ATTEMPTS} = $n_a1;
    $blockref->{N_ATTEMPTS} = $n_a;
    $blockref->{N_SUCCESSES} = $n_s;
    $blockref->{N_FAILURES} = $n_f;
    $blockref->{N_RETRIES} = $n_r;

    $r{n_blocks} = scalar grep $time >= $_->{BLOCK_CREATE}, values %$blocks;

    $r{n_ideal1} = POSIX::floor(scalar @{$totals->{ATTEMPTS}}  / $avg_block_size);
    $r{n_ideal1} = $r{n_blocks} if $r{n_ideal1} > $r{n_blocks};

    $r{n_ideal2} = POSIX::floor(scalar @{$totals->{SUCCESSES}} / $avg_block_size);
    $r{n_ideal2} = $r{n_blocks} if $r{n_ideal2} > $r{n_blocks};

    # compute block counts
    foreach my $block ( values %$blocks ) {
	next unless $block->{N_FILES} && $block->{N_ATTEMPTS};
	$r{n_pot}++ if $block->{N_UNQ_ATTEMPTS} == $block->{N_FILES};
	$r{n_act}++ if $block->{N_SUCCESSES} == $block->{N_FILES};

	$r{n_a}++   if $block->{N_UNQ_ATTEMPTS} > 0;
	my $pct_a = $block->{N_UNQ_ATTEMPTS} / $block->{N_FILES};
	$r{n_a25}++  if $pct_a >  0.00 && $pct_a <  0.25;
	$r{n_a50}++  if $pct_a >= 0.25 && $pct_a <  0.50;
	$r{n_a75}++  if $pct_a >= 0.50 && $pct_a <  0.75;
	$r{n_a100}++ if $pct_a >= 0.75 && $pct_a <= 1.00;

	$r{n_s}++ if $block->{N_SUCCESSES} > 0;
	my $pct_s = $block->{N_SUCCESSES} / $block->{N_FILES};
	$r{n_s25}++  if $pct_s >  0.00 && $pct_s <  0.25;
	$r{n_s50}++  if $pct_s >= 0.25 && $pct_s <  0.50;
	$r{n_s75}++  if $pct_s >= 0.50 && $pct_s <  0.75;
	$r{n_s100}++ if $pct_s >= 0.75 && $pct_s <= 1.00;

	$r{n_f}++ if $block->{N_FAILURES} > 0;
	my $pct_f = $block->{N_FAILURES} / $block->{N_ATTEMPTS};
	$r{n_f25}++  if $pct_f >  0.00 && $pct_f <  0.25;
	$r{n_f50}++  if $pct_f >= 0.25 && $pct_f <  0.50;
	$r{n_f75}++  if $pct_f >= 0.50 && $pct_f <  0.75;
	$r{n_f100}++ if $pct_f >= 0.75 && $pct_f <= 1.00;

	$r{n_r}++ if $block->{N_RETRIES} > 0;
	my $pct_r = $block->{N_RETRIES} / $block->{N_ATTEMPTS};
	$r{n_r25}++  if $pct_r >  0.00 && $pct_r <  0.25;
	$r{n_r50}++  if $pct_r >= 0.25 && $pct_r <  0.50;
	$r{n_r75}++  if $pct_r >= 0.50 && $pct_r <  0.75;
	$r{n_r100}++ if $pct_r >= 0.75 && $pct_r <= 1.00;
    }
    # finally, output the current statistics
    print join(',', 
	       strftime ("%Y-%m-%d %H:%M:%S", gmtime($time)), # timestamp
	       sprintf("%.3f", ($time - $start) / 60),        # minute
	       map( { $r{$_} } @r)), "\n";                    # result data
    #print Dumper(\%r), "\n";
}
close LOG;

&disconnectFromDatabase($self, $dbh, 1);
