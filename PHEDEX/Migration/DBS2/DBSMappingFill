#!/usr/bin/env python
#
# Update DBS2 with block replica information

import sys
from fnmatch import filter
import re
import traceback
from string import lstrip
from DBSAPI.dbsApi import DbsApi
from phedex import PhedexApi

def createMappings(newName):
  n_b = 0
  print "Mapping dataset with new name ", newName
  dataset_mappings, block_mappings = findMappings(newName)

  if not dataset_mappings or not block_mappings:
    raise Exception("Could not make any mappings for dataset %s" % newName)

  for dm in dataset_mappings:
    old, new = dm.split(',')
    addDatasetMapping(old, new)

  for bm in block_mappings:
    old, new = bm.split(',')
    addBlockMapping(old, new)

  return len(dataset_mappings), len(block_mappings)

def findMappings(dataset):
  p = re.compile('^/([^/]+)/([^/]+)(/[^/]+|\#[^\#]+)$')
  parts = p.findall(dataset)
  if not parts: raise Exception("Bad dataset format")
  prim, proc, tier = parts[0]
  #tier = tier.lstrip('/')
  tier = "*" # Specifying tier does not work in DBS API

  print "Looking up %s %s %s in DBS2" % (prim, proc, tier)

  dataset_mappings = set()
  block_mappings = set()

  dbsDatasets = dbs.listProcessedDatasets(patternPrim=prim, patternProc=proc, patternDT=tier)
  if not dbsDatasets:  raise Exception("No datasets found for %s %s %s" % (prim, proc, tier))
                    
  for dataset in dbsDatasets:
    n_ds, n_b, n_br, n_f = 0, 0, 0, 0
    n_ds += 1
                                       
    if not dataset['PathList']:  raise Exception("No path for dataset %s %s %s" % (prim, proc, tier))
    new_dataset = dataset['PathList'][0] # Only the first path!  What if there are multiple?
    
    dbsBlocks = dbs.listBlocks(dataset=new_dataset)
    if not dbsBlocks:  raise Exception("No blocks found in dataset %s" % path)
    
    for block in dbsBlocks:
      new_block = block['Name']
      dbsFiles = dbs.listFiles(blockName=new_block)
      if not dbsFiles:
        warn("No files found in block %s, skipping" % block['Name'])
        continue

      for file in dbsFiles:
        filename = file['LogicalFileName']
        row = [ getMappingByFile(filename) ]
        
        if not row[0]:
          print "DBS file %s not found in TMDB" % filename
        else:
          old_dataset, old_block, phedex_file = row[0]
          dataset_mappings.add(old_dataset+","+new_dataset)
          block_mappings.add(old_block+","+new_block)

  return dataset_mappings, block_mappings
          
def warn(message):
  print "WARN:  ", message

def getMappingByFile(filename):
  cur = phedex.con.cursor()
  if ( mode == 'copy-rename' or mode == 'copy-as-is' ):
    sql = """select ds.name, b.name, f.logical_name
           from xt_dps_dataset ds
             join xt_dps_block b on b.dataset = ds.id
             join xt_dps_file f on f.inblock = b.id
             where f.logical_name = :filename
         """
      
  elif ( mode == 'in-place-rename' ):
    sql = """select ds.name, b.name, f.logical_name
           from t_dps_dataset ds
             join t_dps_block b on b.dataset = ds.id
             join t_dps_file f on f.inblock = b.id
             where f.logical_name = :filename
         """   
  cur.execute(sql, {'filename':filename})
  return cur.fetchone() 

def addDatasetMapping(old, new):
  cur = phedex.con.cursor()
  sql = """insert into t_migration_dataset_map (old, new)
                 values (:old, :new)
        """
  cur.execute(sql, {'old':old, 'new':new})

def addBlockMapping(old, new):
  cur = phedex.con.cursor()
  sql = """insert into t_migration_block_map (old, new)
                 values (:old, :new)
        """
  cur.execute(sql, {'old':old, 'new':new})

  
def parseDatasetNameMap(mapfile):
  map = {}
  f = open(mapfile)
  for line in f:
    if not line.startswith('/'): continue
    a = re.split("\s+", line)
    map[a[0]] = a[1]
  f.close
  return map
  
      

from optparse import OptionParser

usage =  "usage: %prog [options]\n"
usage += "\nTakes a dataset map file and fills TMDB with dataset mapping and block mappings"
parser = OptionParser(usage=usage)
parser.add_option('-f', '--mapfile', dest='mapfile', help='Old dataset to New Dataset name mapping file')
parser.add_option('-u', '--url', dest='url', help='DBS write URL')
parser.add_option('-c', '--phedex_connect', dest='phedex_connect', help='PhEDEx connection string')
parser.add_option('-m', '--migration_mode', dest='migration_mode', help='TMDB migration mode: <copy-rename> <copy-as-is> <in-place-rename>')
(opts, args) = parser.parse_args()

if not opts.url or not opts.mapfile or not opts.phedex_connect or not opts.migration_mode:
  print "Missing arguments.  Seek help.  (-h)"
  sys.exit(0)

if (opts.migration_mode != 'copy-rename' and opts.migration_mode != 'copy-as-is' and  opts.migration_mode !='in-place-rename'): 
  print "Migration mode are: copy-rename or copy-as-is or in-place-rename"
  sys.exit(0)
  
dbs = DbsApi({'url':  opts.url})
phedex = PhedexApi(opts.phedex_connect)

mode = opts.migration_mode 

map = parseDatasetNameMap(opts.mapfile)
tried = set()
t_ds = 0
t_b = 0
for dataset, newName in map.iteritems():
  try:
    if newName in tried:
      raise Exception("Already attempted this dataset mapping")
    n_ds, n_b = createMappings(newName)
    t_ds += n_ds;  t_b += n_b
  except Exception, ex:
    print "ERROR:  ",ex

phedex.con.commit()


print "Added mapping for %s datasets and %s blocks" % (t_ds, t_b)
sys.exit(0)
