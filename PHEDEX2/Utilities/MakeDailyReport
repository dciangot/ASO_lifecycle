#!/usr/bin/env perl

##H Generate daily PhEDEx status- and health report.  Various issues of
##H concern to the administrators of the system are reported in a nice
##H convenient summary which can be archived and/or mailed out.
##H
##H The report includes the following information:
##H   - Database space usage, quota limits.
##H   - Average transfer performance and pending queues.
##H   - Statistics on sites preventing block deactivation.
##H   - Consistency check warnings on the tables.
##H
##H Usage:
##H   MakeDailyReport -db FILE[:SECTION] [-upto TIME]
##H
##H -db        database connection configuration parameter file
##H -upto      transfer report result up to TIME (unix time stamp)
##H
##H The output goes to the standard output in plain text format.

# Process command line arguments.
my %args;
use List::Util qw(reduce min max sum);
use Getopt::Long;
use PHEDEX::Core::Help;
use PHEDEX::Core::Timing;
use PHEDEX::Core::Net;
use PHEDEX::Core::DB;
use POSIX;
&GetOptions ("db=s"        => \$args{DBCONFIG},
             "upto=s"      => \$args{UPTO},
	     "help|h"      => sub { &usage() });

# Check arguments.
if (@ARGV || !$args{DBCONFIG})
{
    die "Insufficient parameters, use -h for help.\n";
}

        my ($from, $to, $bin, $width,
	    $xfiles, $xbytes, $pfiles, $pbytes,
       	    $tfiles, $ffiles) = @a;
use constant FROM	  => 0;
use constant TO 	  => 1;
use constant BIN	  => 2;
use constant WIDTH	  => 3;
use constant XFER_FILES   => 4;
use constant XFER_BYTES   => 5;
use constant PEND_FILES   => 6;
use constant PEND_BYTES   => 7;
use constant SUCC_START   => 8;
use constant SUCC_ERROR   => 9;
use constant SUCC_SUCCESS => XFER_FILES;

my $dbh = &connectToDatabase (\%args);

print "PhEDEx status report for $args{DBSECTION} ($args{DBH_DBUSER}\@$args{DBH_DBNAME})\n",
      "generated at @{[strftime('%Y-%m-%d %H:%M:%S', gmtime())]} GMT",
      " by <@{[scalar(getpwuid($<)) . '@' . &getfullhostname()]}>.\n\n";

######################################################################
# Database table used space statistics

print "#" x 70, "\n";
print "# Table used space\n\n";
print sprintf ("%-8s %-31s %-31s %10s %10s %10s\n",
	       "TYPE", "SEGMENT", "TABLESPACE",
	       "MEGABYTES", "BLOCKS", "EXTENTS");
print "-" x 8, " ", "-" x 31, " ", "-" x 31, " ",
      "-" x 10, " ", "-" x 10, " ", "-" x 10, "\n";

my $qtables = PHEDEX::Core::DB::dbexec($dbh, qq{
  select * from table(func_table_used_space()) });
while (my ($type, $object, $tspace, $bytes, $blocks, $extents) = $qtables->fetchrow())
{
    print sprintf ("%-8s %-31s %-31s %10.2f %10d %10d\n",
	    	   $type, $object, $tspace,
		   $bytes/(1000**2), $blocks, $extents);
}
$qtables->finish();

print "\n\n";

######################################################################
# Database tablespace used, available statistics

print "#" x 70, "\n";
print "# Tablespace used space\n\n";
print sprintf ("%-31s %15s %15s %15s %15s %-6s\n", "TABLESPACE", "USED_MEGABYTES",
	       "USED_BLOCKS", "FREE_MEGABYTES", "FREE_BLOCKS", "STATUS");
print "-" x 31, " ", "-" x 15, " ", "-" x 15, " ", "-" x 15, " ", "-" x 15, " ", "-" x 6, "\n";

my $qtspace = PHEDEX::Core::DB::dbexec($dbh, qq{
  select * from table(func_tablespace_used_space()) });
while (my ($tspace, $bytes_used, $blocks_used,
	   $bytes_free, $blocks_free) = $qtspace->fetchrow())
{
    print sprintf ("%-31s %15.2f %15d %15.2f %15d %-6s\n",
	    	   $tspace, $bytes_used/(1000**2), $blocks_used,
		   $bytes_free/(1000**2), $blocks_free,
	   	   $bytes_free < 100*(1000**2) ? "FULL!" : "OK");
}
$qtspace->finish();

print "\n\n";

######################################################################
# Database tablespace used, available statistics

print "#" x 70, "\n";
print "# Recent transfer status\n",
      "#\n",
      "# XFER_MBPS_TOT      Aggregate transfer rate over the period\n",
      "# XFER_GB_TOT        Total amount in gigabytes transferred\n",
      "# XFER_F_TOT         Total number of files transferred\n",
      "# XFER_SUCC_TOT      Total percentage of successful transfers\n",
      "# XFER_HRS           Count of hours in which transfers have completed\n",
      "# XFER_DAYS          Count of days in which transfers have completed\n",
      "# XFER_MBPS_HRMIN    Minimum average hourly transfer rate in MB/s\n",
      "# XFER_MBPS_HRMAX    Maximum average hourly transfer rate in MB/s\n",
      "# XFER_MBPS_HRAVG    Average average hourly transfer rate in MB/s\n",
      "# XFER_SUCC_HRMIN    Minimum hourly percentage of transfer successes\n",
      "# XFER_SUCC_HRMAX    Maximum hourly percentage of transfer successes\n",
      "# WAIT_GB_CHNG       Aggregate difference in pending queue in gigabytes over period\n",
      "# WAIT_GB_FIN        Pending queue in gigabytes at the end of period\n",
      "# WAIT_F_FIN         Pending queue in number of files at the end of period\n",
      "# WAIT_GB_MIN        Minimum size of pending queue during the period\n",
      "# WAIT_GB_MAX        Maximum size of pending queue during the period\n",
      "# WAIT_GB_AVG        Average size of pending queue during the period\n";

foreach my $prevdays (1, 7, 14, 30, 90, 365)
{
    my ($timelow, $timemax, $timespan, %perf, @perf, %success);
    my $now = $args{UPTO} || &mytimeofday();
    my $lowlimit = (int($now/86400)-$prevdays)*86400;
    $now = $lowlimit + $prevdays*86400;

    my $qperf = &dbexec($dbh, qq{
        select
           f.name,
           t.name,
            trunc(he.timebin/3600)*3600,
            3600,
            nvl(sum(he.done_files),0),
            nvl(sum(he.done_bytes),0),
            nvl(sum(hs.pend_files) keep (dense_rank last order by hs.timebin asc),0),
            nvl(sum(hs.pend_bytes) keep (dense_rank last order by hs.timebin asc),0),
            nvl(sum(he.try_files),0),
            nvl(sum(he.fail_files),0)
        from t_history_link_events he
          join t_adm_node f on f.id = he.from_node
          join t_adm_node t on t.id = he.to_node
          join t_history_link_stats hs on hs.from_node=he.from_node and hs.to_node=he.to_node
                                 and hs.timebin=he.timebin and hs.priority=he.priority
          where he.timebin >= :limit
          and he.timebin < :upto
          and f.name not like '%MSS'
        group by f.name, t.name, trunc(he.timebin/3600)*3600, 3600},
        ":limit" => $lowlimit, ":upto" => $now);
    while ( my @a = $qperf->fetchrow() )
    {
        my $bin = $a[BIN];
	if (! defined $timemax || $bin > $timemax)
	{
            $timemax = $bin;
	    $timespan = $a[WIDTH];
	}
	if (! defined $timelow || $bin < $timelow)
	{
            $timelow = $bin;
	}
#       Saving an array instead of a hashref saves a bit of memory because of the keys, even
#       though duplicate keys are shared, so it doesn't save a great deal. But more later...
        push @perf, "@a";
    }

    while ( $_ = shift @perf )
    {
      my @a = split(' ',$_);
      my ($to,$from) = @a[TO,FROM];
#     Shrink the TO and FROM fields, but do not eliminate them or later splits will fail!
#     This saves about 10% of the memory over and above the other hacks
      $a[TO] = $a[FROM] = '.';
#     This is the big memory-saver. All those numbers represented as a string take up about
#     a third of the space they do as internally-represented integers.
#     The flip-side of this is that you waste a lot of CPU splitting the string and joining
#     the array when you want to read or store the values. You can't win them all!
      push @{$perf{$to}{$from}}, join(' ',@a);;
    }

    # Make sure the time bounds are defined in case the period was empty
    if (! defined $timemax)
    {
	$timespan = 300;
	$timelow = $lowlimit;
	$timemax = $now - $timespan;
    }
    $timespan += $timemax - $timelow;

    # Print out the headings
    print "\n# $prevdays-day period from ",
          strftime ('%Y-%m-%d %H:%M:%S', gmtime(int($timelow))), " to ",
          strftime ('%Y-%m-%d %H:%M:%S', gmtime(int($timelow+$timespan-1))), "\n\n";
    print sprintf ("%-25s" . " %15s" x 18 . "\n",
	           "DESTINATION/FROM",
	           "XFER_MBPS_TOT", "XFER_GB_TOT", "XFER_F_TOT", "XFER_SUCC_TOT",
		   "XFER_HRS", "XFER_DAYS",
		   "XFER_MBPS_HRMIN", "XFER_MBPS_HRMAX", "XFER_MBPS_HRAVG",
		   "XFER_SUCC_HRMIN", "XFER_SUCC_HRMAX",
	           "WAIT_GB_CHNG", "WAIT_GB_FIN", "WAIT_F_FIN",
		   "WAIT_GB_MIN", "WAIT_GB_MAX", "WAIT_GB_AVG",
	           "EST_DAYS_LEFT");
    print "-" x 25, (" ", "-" x 15) x 18, "\n";

    # Build array of link structures we want to report on.  This is first
    # a summary row for each destination, then individual links to that
    # destination.
    my @links;
    foreach my $to (sort keys %perf)
    {
	my @from = sort keys %{$perf{$to}};
	push (@links, [ $to, map { $perf{$to}{$_} } @from ]);
	push (@links, [ ". $_", $perf{$to}{$_} ]) for @from;
    }

    # Now build a report for each link.
    foreach my $link (@links)
    {
	my $label = shift (@$link);
        my %stats = (XFER_MBPS_TOT => 0, XFER_GB_TOT => 0, XFER_F_TOT => 0, XFER_SUCC_TOT => 'N/A',
		     XFER_HRS => 0, XFER_DAYS => 0,
		     XFER_SUCCESS => { START => 0, ERROR => 0, SUCCESS => 0, RATIO => undef },
	             XFER_MBPS_HRMIN => 0, XFER_MBPS_HRMAX => 0, XFER_MBPS_HRAVG => 0,
	             XFER_SUCC_HRMIN => 0, XFER_SUCC_HRMAX => 0,
		     WAIT_GB_CHNG => 0, WAIT_GB_FIN => 0, WAIT_F_FIN => 0,
		     WAIT_GB_MIN => 0, WAIT_GB_MAX => 0, WAIT_GB_AVG => 0);

	# Bin quality hourly and calculate statistics
        my %hourly = ();

        foreach my $array (@$link)
        {
            foreach my $vs (@$array)
	    {
#		Need to recover the array from the string by splitting it
		my @v = split(' ',$vs);
#		Positional notation using named constants. Handle with care!
	        my $hour = $v[BIN];
	        $hourly{$hour}{XFER_SUCCESS} ||= { START => 0, SUCCESS => 0, ERROR => 0, RATIO => undef };
	        $hourly{$hour}{START} += $v[SUCC_START];
	        $hourly{$hour}{ERROR} += $v[SUCC_ERROR];
	        $hourly{$hour}{SUCCESS} += $v[SUCC_SUCCESS];

	        $stats{XFER_SUCCESS}{START} += $v[SUCC_START];
	        $stats{XFER_SUCCESS}{ERROR} += $v[SUCC_ERROR];
	        $stats{XFER_SUCCESS}{SUCCESS} += $v[SUCC_SUCCESS];
	    }
        }

	foreach my $v ($stats{XFER_SUCCESS}, values %hourly)
	{
#	    if ($$v{START}) {
#		$$v{RATIO} = $$v{SUCCESS} / $$v{START};
	    # Note:  START = try_bytes is not a simultaneous event with SUCCESS and ERROR
	    # try_bytes is the number of transfers started in that time period
	    # done_bytes and error_bytes is the number of successful / unsuccessful transfers in that period
	    # they do not represent the same file transfers.  one should not use them together to compute RATIO
	    if ($$v{SUCCESS} || $$v{ERROR}) {
		$$v{RATIO} = $$v{SUCCESS} / ($$v{SUCCESS} + $$v{ERROR});
	    } else {
		$$v{RATIO} = undef;
	    }
	}

	my $succ_min = reduce { $$a{RATIO} < $$b{RATIO} ? $a : $b }
		       grep(defined $$_{RATIO}, values %hourly);
	my $succ_max = reduce { $$a{RATIO} > $$b{RATIO} ? $a : $b }
		       grep(defined $$_{RATIO}, values %hourly);
        $stats{XFER_SUCC_HRMIN} = &naformat($$succ_min{RATIO}, "%.0f%%", 100);
        $stats{XFER_SUCC_HRMAX} = &naformat($$succ_max{RATIO}, "%.0f%%", 100);
        $stats{XFER_SUCC_TOT} = &naformat($stats{XFER_SUCCESS}{RATIO}, "%.0f%%", 100);

	# Bin transfers hourly and calculate statistics.  The binning is
	# seeded from success statistics so we correctly report the hours
	# in which transfers took place.  After this seeding we report
	# hours in which nothing happened to avoid reporting hours with
	# non-zero pending queue as hours of transfer.
        $hourly{$_} = 0 for keys %hourly;
        foreach my $array (@$link)
        {
            foreach my $vs (@$array)
	    {
		my @v = split(' ',$vs);
		next if ! $v[XFER_FILES];

	        my $hour = $v[BIN];
	        $hourly{$hour} ||= 0;
		$hourly{$hour} += $v[XFER_BYTES];

		$stats{XFER_GB_TOT} += $v[XFER_BYTES] / (1000**3);
		$stats{XFER_F_TOT} += $v[XFER_FILES];
	    }
	}

	my $xfer_min = min values %hourly;
	my $xfer_max = max values %hourly;
	my $xfer_avg = (%hourly
			? (sum (values %hourly) / scalar (values %hourly))
			: undef);
	my %xfer_hours = map { (int($_/3600) => 1) } keys %hourly;
	my %xfer_days = map { (int($_/86400) => 1) } keys %hourly;
        $stats{XFER_MBPS_HRMIN} = ($xfer_min || 0) / (1000**2) / 3600;
        $stats{XFER_MBPS_HRMAX} = ($xfer_max || 0) / (1000**2) / 3600;
        $stats{XFER_MBPS_HRAVG} = ($xfer_avg || 0) / (1000**2) / 3600;
        $stats{XFER_MBPS_TOT} = $stats{XFER_GB_TOT} * 1000 / $timespan;
	$stats{XFER_HRS} = scalar keys %xfer_hours;
	$stats{XFER_DAYS} = scalar keys %xfer_days;

	# Bin pending queue hourly and calculate statistics
        %hourly = ();
        foreach my $array (@$link)
        {
            foreach my $vs (@$array)
	    {
		my @v = split(' ',$vs);
	        $hourly{$v[BIN]} ||= { BIN => $v[BIN], FILES => 0, BYTES => 0 };
		$hourly{$v[BIN]}{FILES} += $v[PEND_FILES];
		$hourly{$v[BIN]}{BYTES} += $v[PEND_BYTES];
	    }
	}

	my $pend_min = reduce { $$a{BYTES} < $$b{BYTES} ? $a : $b } values %hourly;
	my $pend_max = reduce { $$a{BYTES} > $$b{BYTES} ? $a : $b } values %hourly;
	my $pend_avg = &avg (map { $$_{BYTES} } values %hourly);
        my @pendtimes = sort { $a <=> $b } keys %hourly;
        my $pendmin = $pendtimes[0];
        my $pendmax = $timemax;

        $stats{WAIT_GB_MIN} = ($$pend_min{BYTES} || 0) / (1000**3);
        $stats{WAIT_GB_MAX} = ($$pend_max{BYTES} || 0) / (1000**3);
        $stats{WAIT_GB_AVG} = ($pend_avg || 0) / (1000**3);
        $stats{WAIT_GB_FIN} = ($hourly{$pendmax}{BYTES} || 0) / (1000**3);
        $stats{WAIT_F_FIN}  = ($hourly{$pendmin}{FILES} || 0);
        $stats{WAIT_GB_CHNG} = (($hourly{$pendmax}{BYTES} || 0)
			        - ($hourly{$pendmin}{BYTES} || 0)) / (1000**3);

	# Print out results
        print sprintf ("%-25s"
	               . " %15.3f %15.3f %15d %15s"
		       . " %15d %15d"
		       . " %15.3f %15.3f %15.3f"
		       . " %15s %15s"
		       . " %15.3f %15.3f %15d"
		       . " %15.3f %15.3f %15.3f"
		       . " %s\n",
	               $label,
		       $stats{XFER_MBPS_TOT}, $stats{XFER_GB_TOT}, $stats{XFER_F_TOT}, $stats{XFER_SUCC_TOT},
		       $stats{XFER_HRS}, $stats{XFER_DAYS},
		       $stats{XFER_MBPS_HRMIN}, $stats{XFER_MBPS_HRMAX}, $stats{XFER_MBPS_HRAVG},
		       $stats{XFER_SUCC_HRMIN}, $stats{XFER_SUCC_HRMAX},
		       $stats{WAIT_GB_CHNG}, $stats{WAIT_GB_FIN}, $stats{WAIT_F_FIN},
		       $stats{WAIT_GB_MIN}, $stats{WAIT_GB_MAX}, $stats{WAIT_GB_AVG},
	   	       ($stats{XFER_MBPS_TOT} && $stats{WAIT_GB_FIN}
		        ? sprintf ("%15.3f", $stats{WAIT_GB_FIN} / ($stats{XFER_MBPS_TOT}*86400/1000))
	   	        : !$stats{WAIT_GB_FIN} ? sprintf ("%15.3f", 0)
		        : sprintf ("%15s", "N/A")));
    }
}

print "\n\n";

######################################################################
# Sites preventing block activation

print "#" x 70, "\n";
print "# Sites preventing block deactivation\n\n";
print sprintf ("%-20s %15s %15s %15s\n", "DESTINATION",
	       "BLOCKS", "REPLICAS", "GIGABYTES");
print "-" x 20, (" ", "-" x 15) x 3, "\n";

my $qblocks = &dbexec($dbh, qq{
    select
        n.name,
	count(b.name),
	sum(b.files - br.node_files),
	sum(b.bytes - br.node_bytes)
    from t_dps_block b
      join t_dps_block_replica br on br.block = b.id
      join t_adm_node n on n.id = br.node
    where b.is_open = 'n'
      and br.is_active = 'y'
      and br.dest_files > 0
      and br.node_files != br.dest_files
    group by n.name
    order by 2 desc, 4 desc});
while (my ($node, $blocks, $files, $bytes) = $qblocks->fetchrow())
{
    print sprintf ("%-20s %15d %15d %15.2f\n",
	           $node, $blocks, $files, $bytes/(1000**3));
}

print "\n\n";

######################################################################
# Consistency checks

print "#" x 70, "\n";
print "# Consistency checks\n\n";

my $errors = 0;
my $qtrdups = &dbexec($dbh, qq{
    select xt.to_node, xt.fileid, f.logical_name
    from t_xfer_task xt
      join t_xfer_file f
        on f.id = xt.fileid
      join t_xfer_replica xr
        on xr.fileid = xt.fileid
       and xr.node = xt.to_node
    order by xt.to_node, f.logical_name});
while (my ($to, $id, $lfn) = $qtrdups->fetchrow ())
{
    print "WARNING: destination replica exists for transfer of $id to $to ($lfn)\n";
    ++$errors;
}

print "(Nothing to report)\n" if ! $errors;

print "\n\n";
######################################################################
&disconnectFromDatabase(\%args, $dbh, 1);
exit 0;

sub avg
{
    my (@values) = @_;
    my $sum = 0; my $defined = 0;
    foreach my $val (@values)
    {
	next if ! defined ($val);
	$sum += $val;
	++$defined;
    }
    return $defined ? ($sum / $defined) : undef;
}

sub naformat
{
    my ($value, $format, $factor) = @_;
    return 'N/A' if ! defined $value;
    return sprintf($format, $value * $factor);
}
