1) Set up your DBParam
 - by default, you should use a section called PrivateTestbed, configured 
   to point at whatever instance you
   intend to use. This makes it harder to accidentally use the Productoin, 
   Dev, or Debug instances.
 - better still, strip out all unwanted entries from your DBParam, so it 
   only has the testbed you are working on

2) Set up the env.sh file correctly:
 - take a look at the example here and make sure the same environment
   variables are defined, but correct them for your setup
 - note that you need the T0 perl libraries in your PERL5LIB somewhere
 - your DBParam must be somewhere readable by your batch jobs, so it 
   should be on your _private_ AFS space

3) Source your environment, and check it!
 - run '. ./env.sh', then
 - run
	sqlplus $($PHEDEX_ROOT/Utilities/OracleConnectId -db $PHEDEX_DBPARAM)
 - you should find yourself connected to your database

4) Initialise your schema
 - run ./ResetSchema.sh, which you will find in this directory

5) Set up your nodes, links, and groups
 - run
	./SetupNodes -db $PHEDEX_DBPARAM 1:T0 8:T1 50:T2
   this creates one T0, 8 T1s, and 50 T2s, with the corresponding links.
 - note that the T1s are maximally linked, all to each other. The T2s are 
   each linked to all the T1s, but not to each other.
 - run ./post-setup.sh to insert the groups

6) Start your central agents
 - best to do this on a dedicated vobox.
 - ./central-agents start

7) Start the site agents
 - submit these to LSF in batches of 5 per job. Use the cmsphedex queue
 - ./submit.sh 59 # (59 is the total number of agents, 1xT0+8xT1+50xT2)

8) Check the status by watching the 'logs' directory for *.tail files

9) Inspect the jobs more closely
 - by running ./check-hosts.sh, which submits batch jobs to check what is
   happening on the batch nodes. One potential problem is that since we 
   run agents as daemons, the parent batch job may be killed but leave the
   agents running. You need to check the logfiles for that.
 - the check-hosts.sh jobs write their logfiles in the logs directory

10) stop the agents when necessary
 - for site agents, run "./check-hosts.sh kill". Wait for the jobs to run,
   that can take several minutes
 - for central agents, run "./central-agents.sh stop"

11) For the advanced user...
 - you can play with the LinkFailureRates.conf file, which defines failure
   rates per link. Once agents start they copy this to the failconf 
   directory (which is created if it isn't already there), so you can play
   with failure modes in fine detail (from any source to any destination,
   individually)
 - you can shuffle the failing links by hand with the fail-shuffle.pl 
   script, which randomly breaks and repairs links while the system is 
   running
 - you can edit the Lifecycle.conf file while the lifecycle agent is 
   running, to change the parameters of the dataflow
 - you can change the Config.Site file to use the FTS backend with faked
   transfers, with per-transfer failure rates. That goes beyond the scope 
   of this README
