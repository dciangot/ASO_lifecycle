# This is where it all happens...
# This file is executable Perl code, and its sole purpose is to define the
# %Lifecycle::Lite hash (a Perl hash is like a Python dictionary). This
# hash must contain certain structures that drive the Lifecycle agent, and
# also contains the data needed to drive the workflows.
#
# If you make changes to this file, you should check that the syntax is
# correct by running 'perl -c <this-file-name>' and checking that there
# are no errors.
%Lifecycle::Lite =
(
  Name		=> 'Lifecycle Lite', # don't worry about this

# We define sections for Globals, Templates, Defaults, and Workflows.
# Each Workflow represents an instance of a task-chain, with all the
# parameters it needs to drive it. For convenience, a Workflow can pick up
# defaults from a Template. If any parameter values are left unresolved,
# they are picked up from the Defaults, or if not defined there, from the
# Globals.
# This is not strictly an object-oriented hierarchy, but it sure cuts down
# on the typing needed to instantiate and modify a complex system.

# These are true globals. Overriding these per Workflow does not make sense
  Quiet		=> 0,
  Verbose	=> 0,
  Debug		=> 0,
  Dummy		=> 0,   # Just run the framework. Used only for specialised
			# debugging (of the LifeCycle agent itself)
  Jitter	=> 0.5, # Spread delay-times for workflow events by this factor
  CycleSpeedup	=>   1, # speed up time. 1 => real-time, 24 => one day per hour
  Suspend	=>   0, # set to 1 to suspend new workflows from starting,
                        # but allow existing workflows to run to completion
  NJobs		=>  10, # degree of parallelism

# Also true globals, but these make sense to override. Providing values here
# is just a convenient way to avoid having to repeat them everywhere.
  CycleTime	=> 60,
  NCycles	=> 1, # < 0 => infinite, > 0 to limit

  KeepInputs	=> 1, # keep the  input files of successful jobs?
  KeepOutputs	=> 1, # keep the output files of successful jobs?
  KeepLogs	=> 1, # keep the    log files of successful jobs?
  KeepFailedInputs	=> 1, # keep the  input files of failed jobs?
  KeepFailedOutputs	=> 1, # keep the output files of failed jobs?
  KeepFailedLogs	=> 1, # keep the    log files of failed jobs?

# After the global values, define the Templates and their default values
  Templates =>
  {
    'PhedexDBSDASIntegrationWorkflow' =>
    {
#     These override the global defaults
      CycleTime => 1000,
      NCycles	=> 1,

#     Event names are arbitrary keys, used elsewhere to define what it means
#     to execute that event. Typically, that means specifying an interval
#     between events and a script or Perl module to handle the event
      Events    => [ 'check', 'payload_provider', 'errorhandler', 'Inject', 'dbs3IntroduceFailures', 'dbs3BulkInsert', 'das_lifecycle', 'compare_das', 'compare_dbsphedex', 'compare_phedexdbs', ],
      Intervals => {
        'payload_provider' => undef, # fire immediately this workflow starts
	'dbs3IntroduceFailures' => 1, # fire a few seconds after the previous step
        'dbs3BulkInsert' => 1, # fire a few seconds after the previous step
	'das_lifecycle'  => 300,
      },

#     There is also arbitrary data, needed to get the workflow going. In this
#     case, we specify a directory to start drilling down from
      NumberOfDatasets => 1,
      NumberOfBlocks => 3,
      NumberOfFiles => 10,
      NumberOfRuns => 5,
      NumberOfLumis => 10,
      PhedexDBSName => "http://cmsdoc.cern.ch/cms/aprom/DBS/CGIServer/query",
      NumberOfCycles => 1,
      NumberOfWorkflows => 1,
      PhedexSkipFileFail => 0.1,
      PhedexChangeCksumFail => 0.1,
      PhedexChangeSizeFail => 0.1,
      DBSSkipFileFail => 0.1,
      DBSChangeCksumFail => 0.1,
      DBSChangeSizeFail => 0.1, 
    },
#   'AnotherTemplate' => # I can add more templates, as many as I like
#   {
#     ...
#   },
  },

# Default values are applied if they are not defined per Template or Workflow
# This allows setting parameters for all Templates, rather than repeating them
  Defaults =>
  {
	Datasvc     => { # parameters for the Datasvc module constructor
#      url      => 'https://lifecycle01.cern.ch/phedex/datasvc',
#      instance => 'private',
       url      => 'https://phedex-integ.cern.ch/phedex/datasvc', 
       instance => 'integration',
#      Set up your proxy by running 'voms-proxy-init --voms cms --valid 192:00'
       cert_file => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       key_file  => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       ca_file   => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       ca_dir    => $ENV{X509_CERT_DIR}   || '/afs/cern.ch/project/gd/LCG-share2/certificates',
    },

    Exec => {
      'payload_provider'       => 'payload_provider',
      'das_lifecycle'       => './das_lifecycle.py --host=https://das-integ.cern.ch',
      'dbs3IntroduceFailures'  => 'dbs3IntroduceFailures.py',
      'dbs3BulkInsert'         => 'dbs3BulkInsert.py',
    },
	Namespace   => 'PHEDEX::Testbed::Lifecycle',
    	Module => {
      Auth               => 'Datasvc',
      Inject           => 'Datasvc',
      T1Subscribe        => 'Datasvc',
      UpdateSubscription => 'Datasvc',
      srcdelete   => 'Datasvc',
      readJSON   => 'Datasvc',
      makeDataset => 'DataProvider',
      makeBlocks  => 'DataProvider',
      makeFiles   => 'DataProvider',
      addData     => 'DataProvider',
      switch     => 'Functions',
      compare_das     => 'Functions',
      compare_dbsphedex   => 'Functions',
      compare_phedexdbs   => 'Functions',
      check     => 'Functions',
      dascheck     => 'Functions',	
      errorhandler     => 'Functions',			
    },

  },

  Workflows =>
  [
    {
      Name	=> 'PhEDEx DBS and DAS Integration Test',
      Template	=> 'PhedexDBSDASIntegrationWorkflow',   # where to get defaults from
#     I can override defaults here too, if I want
#     InitialRequest => '...',
#     CycleTime => ...,
	InjectionSite             =>    'T1_Test1_Buffer',

    },
#   I can add as many workflows as I like too
#   {
#     Name	=> 'Another workflow',
#     Template	=> 'Another Template',
#   },
  ],
);

# The last statement in the file must be '1;', because of the way Perl loads it
1;
