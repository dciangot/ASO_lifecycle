# This is where it all happens...
# This file is executable Perl code, and its sole purpose is to define the
# %Lifecycle::Lite hash (a Perl hash is like a Python dictionary). This
# hash must contain certain structures that drive the Lifecycle agent, and
# also contains the data needed to drive the workflows.
#
# If you make changes to this file, you should check that the syntax is
# correct by running 'perl -c <this-file-name>' and checking that there
# are no errors.
%Lifecycle::Lite =
(
  Name		=> 'Lifecycle Lite', # don't worry about this

# We define sections for Globals, Templates, Defaults, and Workflows.
# Each Workflow represents an instance of a task-chain, with all the
# parameters it needs to drive it. For convenience, a Workflow can pick up
# defaults from a Template. If any parameter values are left unresolved,
# they are picked up from the Defaults, or if not defined there, from the
# Globals.
# This is not strictly an object-oriented hierarchy, but it sure cuts down
# on the typing needed to instantiate and modify a complex system.

# These are true globals. Overriding these per Workflow does not make sense
  Quiet		=> 0,
  Verbose	=> 0,
  Debug		=> 0,
  Dummy		=> 0,   # Just run the framework. Used only for specialised
			# debugging (of the LifeCycle agent itself)
  Jitter	=> 0.5, # Spread delay-times for workflow events by this factor
  CycleSpeedup	=>   1, # speed up time. 1 => real-time, 24 => one day per hour
  Suspend	=>   0, # set to 1 to suspend new workflows from starting,
                        # but allow existing workflows to run to completion
  NJobs		=>  10, # degree of parallelism

# Also true globals, but these make sense to override. Providing values here
# is just a convenient way to avoid having to repeat them everywhere.
  CycleTime	=> 60,
  NCycles	=> 1, # < 0 => infinite, > 0 to limit

  KeepInputs	=> 0, # keep the  input files of successful jobs?
  KeepOutputs	=> 0, # keep the output files of successful jobs?
  KeepLogs	=> 0, # keep the    log files of successful jobs?
  KeepFailedInputs	=> 0, # keep the  input files of failed jobs?
  KeepFailedOutputs	=> 0, # keep the output files of failed jobs?
  KeepFailedLogs	=> 1, # keep the    log files of failed jobs?

# After the global values, define the Templates and their default values
  Templates =>
  {
    'PhedexDBSDASIntegrationWorkflow' =>
    {
#     These override the global defaults
      CycleTime => 1000,
      NCycles	=> 1,

#     Event names are arbitrary keys, used elsewhere to define what it means
#     to execute that event. Typically, that means specifying an interval
#     between events and a script or Perl module to handle the event
      Events    => [ 'payload_provider', 'dbs3IntroduceFailures','dbs3BulkInsert','switch','errorhandler','Inject', ],

Intervals => {
        'payload_provider' => undef, # fire immediately this workflow starts
        'dbs3IntroduceFailures' => undef,
	'dbs3BulkInsert'=> 1, # fire a few seconds after the previous step

      },

#     There is also arbitrary data, needed to get the workflow going. In this
#     case, we specify a directory to start drilling down from
      NumberOfDatasets => 1,
      NumberOfBlocks => 2,
      NumberOfFiles => 10,
      NumberOfRuns => 5,
      NumberOfLumis => 10,
      NumberOfWorkflows => 1,
      PhedexSkipFileFail => 0.5,
      PhedexChangeCksumFail => 0.5,
      PhedexChangeSizeFail => 0.5,
      DBSSkipFileFail => 0.5,
      DBSChangeCksumFail => 0.5,
      DBSChangeSizeFail => 0.5,
      PhedexDBSName => "http://cmsdoc.cern.ch/cms/aprom/DBS/CGIServer/query",

    },
#   'AnotherTemplate' => # I can add more templates, as many as I like
#   {
#     ...
#   },
  },

# Default values are applied if they are not defined per Template or Workflow
# This allows setting parameters for all Templates, rather than repeating them
  Defaults =>
  { Namespace   => 'PHEDEX::Testbed::Lifecycle',

	Module => {
       	Inject             => 'Datasvc',  
     	switch             => 'Functions',
        errorhandler       => 'Functions',
    	},

	Datasvc     => { # parameters for the Datasvc module constructor
      	url      => 'https://lifecycle03.cern.ch/phedex/datasvc',
      	instance => 'private',
#      Set up your proxy by running 'voms-proxy-init --voms cms --valid 192:00'
       cert_file => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       key_file => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       ca_file => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       ca_dir => $ENV{X509_CERT_DIR}   || '/afs/cern.ch/project/gd/LCG-share2/certificates',
    },

    Exec => {
      'payload_provider'       => 'payload_provider',
      'dbs3BulkInsert'         => 'dbs3BulkInsert.py',
      'dbs3IntroduceFailures'  => 'dbs3IntroduceFailures.py',
    },
  },

  Workflows =>
  [
    {
      Name	=> 'PhEDEx DBS and DAS Integration Test',
      Template	=> 'PhedexDBSDASIntegrationWorkflow',   # where to get defaults from
#     I can override defaults here too, if I want
#     InitialRequest => '...',
#     CycleTime => ...,
#     Injection parameters. Only one, so a simple scalar will do
      InjectionSite             =>    'T0_Test_Buffer',
    },
#   I can add as many workflows as I like too
#   {
#     Name	=> 'Another workflow',
#     Template	=> 'Another Template',
#   },
  ],
);

# The last statement in the file must be '1;', because of the way Perl loads it
1;
